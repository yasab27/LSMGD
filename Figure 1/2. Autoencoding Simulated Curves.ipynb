{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c50084ed-8d44-4e04-bf16-8006049a4b41",
   "metadata": {},
   "source": [
    "##  Autoencoding Simulated Curves \n",
    "\n",
    "In this notebook, we autoencode simulated growth curves leveraging out causal convolutional autoencoder architecture. We provide a full example of autoencoding simple growth curves (logistic) from scratch and then show the final results from a pre-trained model for the complex growth curves. The method of compressing these is identical to simple curves, but training takes longer due to larger training size. \n",
    "\n",
    "The code implementing the neural network architecture is provided in the `models` folder within this directory. We begin by importing necessarily numerical, scientific, and deep learning python libraries: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c02dbd-924b-482e-92d2-0c6e874e483f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For-loop visualization library\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "# Deep learning\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Configure GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "display(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d193a1f-f48a-4f20-bee6-55ef06a31c8c",
   "metadata": {},
   "source": [
    "### Defining a Training Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3ddb9e-5589-42df-845f-a291aaed4332",
   "metadata": {},
   "source": [
    "The first thing we do is define a generic training function which will take any autoencoder model and perform training, i.e. tuning model parameters to minimize the reconstruction loss via stochastic gradient descent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ccb650-7b27-4fa2-af03-f4cbe1279fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, hp, data_loader, debug = False):\n",
    "    \"\"\"Train a given model for a specific type of hyperparamters and data_loader, train\n",
    "    the model and then return the trained model as well as the running losses throughout \n",
    "    training.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model: torch.nn.Module\n",
    "        An untrained model to be optimized.\n",
    "    \n",
    "    hp: dict\n",
    "        A dictionary containing all of the hyperparameters for the system.\n",
    "    \n",
    "    data_loader: torch.utils.DataLoader\n",
    "        A presetup dataloader containing the training data set for the set. \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    model: torch.nn.Module\n",
    "        The trained model after optimization.\n",
    "        \n",
    "    running_losses: list\n",
    "        The loss for each epoch of training. \n",
    "    \"\"\"\n",
    "    \n",
    "    # Store the losses per epoch\n",
    "    running_losses = []\n",
    "    \n",
    "    # Configure optimizer. \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=hp[\"lr\"], weight_decay= hp[\"weight_decay\"])\n",
    "\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    \n",
    "    # Outerloop will iterate through epochs. tqdm function trange provides progressbar\n",
    "    for i in trange(hp[\"epochs\"]):\n",
    "        \n",
    "        \n",
    "        epoch_loss = 0 \n",
    "        # Inner loop iterates through batches\n",
    "        for batch in data_loader:\n",
    "\n",
    "            # Transfer the batch to the GPU\n",
    "            batch = batch.to(device)\n",
    "\n",
    "            if debug:\n",
    "                print(\"BATCH SHAPE: \")\n",
    "                print(batch)\n",
    "\n",
    "            # Zero gradient\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Perform forward pass\n",
    "            pred, code = model(batch)\n",
    "\n",
    "            # Uncomment to verify model prediction shape\n",
    "            if debug:\n",
    "                print(\"PREDI SHAPE: \")\n",
    "                print(batch)\n",
    "\n",
    "            # Compute reconstruction loss\n",
    "            batch_loss = criterion(pred,batch)\n",
    "            \n",
    "            if debug:\n",
    "                print(batch_loss)\n",
    "\n",
    "            # Compute gradient\n",
    "            batch_loss.backward()\n",
    "            \n",
    "\n",
    "            # Take step\n",
    "            optimizer.step()\n",
    "\n",
    "            # Append to running epoch loss\n",
    "            epoch_loss += batch_loss.item()\n",
    "\n",
    "        # Keep running track of losses\n",
    "        if i % 250 == 0:\n",
    "            print(f\"Epoch [{i}]: \" + str(epoch_loss))\n",
    "    \n",
    "        running_losses.append(epoch_loss)\n",
    "\n",
    "    return model, running_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0819ff0b-cd80-4466-9a33-33bf4588166a",
   "metadata": {},
   "source": [
    "### Autoencoding Simple Growth Curves\n",
    "\n",
    "To regenerate the results of figure 1B, we will now autoencode our previously generated simple growth curves. We begin by importing the dataset from the `saved_sims` folder and preparing it for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372e21f7-0466-404c-8664-3c283cd59f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.loadtxt(\"./saved_sims/ex_simple.csv\", delimiter = \",\")\n",
    "\n",
    "# 0-1 Normalize the dataset\n",
    "X = (X - X.min())/(X.max() - X.min())\n",
    "\n",
    "# Transfer it to torch Tensor\n",
    "X = torch.Tensor(X)\n",
    "\n",
    "# Reshape to match the dimensions of the encoder. \n",
    "X = X.reshape(( X.shape[0], 1, -1)).double()\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b97693-8863-4126-977f-11d5f608df2f",
   "metadata": {},
   "source": [
    "#### Configuring the Model Hyperparameters\n",
    "\n",
    "We now import our NN model and configure the hyperparameters, which are all specified in the dictionary `hp`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84acec18-a455-4c08-b642-381206e19684",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = {\n",
    "    \"in_channels\" : 1, # Number of convolutional channels, fixed to 1 for individual curves\n",
    "    \"channels\": 5,  # Number of individual channels per layer, increase to boost model capacity\n",
    "    \"depth\": 10, # Number of Causal layers in the encoder, increase to boost model capacity\n",
    "    \"reduced_size\" : 2, # Size to shrink final embedding to \n",
    "    \"out_channels\" : 2, # ^\n",
    "    \"kernel_size\": 3, # Size of convolutional channels, 3 is the smallest to incorporate local information per time point\n",
    "    \"window_length\": X.shape[2], # Length of input time series\n",
    "    \"lr\": 0.001,  # Learning rate for Adam optimizer\n",
    "    \"epochs\": 1000, # Number of training iteractions\n",
    "    \"batch_size\": 1000,  # Number of training examples in minibatch descent, maxes at training set size\n",
    "    \"weight_decay\":0.0 # Amount of L2 regualirzation for parameters, by default set to zero. \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6629a8-2273-42d9-858f-ac72cda027f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.CausalAE import CausalAE\n",
    "\n",
    "# Create a new model, increase precision to double floating point precision, transfer to GPU\n",
    "model = CausalAE(hp)\n",
    "model.double()\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6a0ee5-a2ce-4f64-a6dc-d87f41f1bf98",
   "metadata": {},
   "source": [
    "We leverage the `pytorch` data loader class to handle our minibatch training method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba3b48b-a2dd-442b-8ce6-8cda9d812339",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(X, batch_size = hp[\"batch_size\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d8faa6-8142-4c6a-a63d-9512471cb027",
   "metadata": {},
   "source": [
    "#### Train the Model\n",
    "\n",
    "Lastly we perform training. We store both the optimized final model but also the running error throughout training. The training function will print off the current L2 error every 250 epochs.  On GPU, this training should take < 10 minutes for the default hyperparameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c0da92-ee41-4290-ac68-61c936a80b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(X, batch_size = hp[\"batch_size\"])\n",
    "\n",
    "trained_model, running_losses = train(model, hp, data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd12e9c4-8721-4b07-aa2e-79a5b6019de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Reconstruction Loss\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.plot(running_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a83df1f-43ba-4b2b-9737-3ecadb201c30",
   "metadata": {},
   "source": [
    "#### Analyzing Simple Curve Autoencoding Results\n",
    "\n",
    "Now we will probe the latent space of this fully trained model. We begin by pulling off trained encoder and decoder modules to enable downstream analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12300792-da62-4fff-a719-089918809d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the encoder and decoder\n",
    "encoder = trained_model.encoder\n",
    "decoder = trained_model.decoder\n",
    "\n",
    "# Switch into evaluation mode\n",
    "encoder.eval()\n",
    "decoder.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b73882-a902-492d-87dc-ba60f2a3fccf",
   "metadata": {},
   "source": [
    "Now we generate and plot embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c68118-f8b3-4c0b-8970-f4001fe2b926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed the dataset, transfer the embeddings to cpu, eliminate the gradient, and push to numpy.\n",
    "embeddings = encoder(X.to(device)).cpu().detach().numpy();\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b547b825-2b77-456b-8a0a-e512094a008c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (5,5))\n",
    "plt.tick_params(\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=False,      # ticks along the bottom edge are off\n",
    "    top=False,  \n",
    "    left = False,\n",
    "    right = False, # ticks along the top edge are off\n",
    "    labelbottom=False,\n",
    "    labelleft = False,\n",
    "    zorder = 20) # labels along the bottom edge are off\n",
    "plt.xlabel(\"Latent Dimension 1\", labelpad= 20)\n",
    "plt.ylabel(\"Latent Dimension 2\", labelpad = 15)\n",
    "plt.scatter(embeddings[:,0], embeddings[:,1], s = 0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de00f433-016a-49d1-ab1e-c8fa746571e6",
   "metadata": {},
   "source": [
    "As we can see, the structure of the data embeds along a clearly 1 dimensional structure, consistent with the underlying 1 dimensional structure of the mechanistic model (varying only in $\\mu$, the growth rate). \n",
    "\n",
    "We can also compare the original and reconstructed growth curves. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db667f7-8e2d-402d-9da8-71ba1f6c1967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose ten curves at random\n",
    "subset = X[np.random.randint(0,X.shape[0], size = 5), :,:].to(device)\n",
    "\n",
    "# Generate embeddings and reconstructions\n",
    "embeddings = model.encoder(subset)\n",
    "recons = model.decoder(embeddings).cpu().detach()\n",
    "\n",
    "# Transfer to cpu and drop gradients to enable plotting\n",
    "embeddings = embeddings.cpu().detach()\n",
    "subset = subset.cpu().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d6fcf4-30a6-4cbf-8786-535ad278c879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot initial, embeddings, and reconstructions\n",
    "fig, axs = plt.subplots(1,3, figsize = (18,6))\n",
    "axs = axs.flatten()\n",
    "\n",
    "axs[0].plot(subset.squeeze().T, color = 'red')\n",
    "axs[0].set_title(\"Originals\")\n",
    "\n",
    "axs[1].scatter(embeddings[:,0],embeddings[:,1], color = \"red\")\n",
    "axs[1].set_xticks([])\n",
    "axs[1].set_yticks([])\n",
    "axs[1].set_title(\"Embeddings\")\n",
    "\n",
    "axs[2].plot(recons.squeeze().T, color = 'red')\n",
    "axs[2].set_title(\"Reconstructions\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2468365-acc8-4e8f-ae1a-a0ddb87a41a8",
   "metadata": {},
   "source": [
    "## Embedding More Complex Growth Curves\n",
    "\n",
    "We now can analyze the results from embedding more complex growth curves. Training can be performed with the same code as before, here we will analyze the results from pre-trained models with `E = 2` and `E = 10`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e823237-83d9-4fe0-b1d8-a9a147bcccf3",
   "metadata": {},
   "source": [
    "#### Analyzing `E = 2` Embeddings\n",
    "\n",
    "First we'll load in the dataset used to generate figures 1C and 1D. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57698709-38f8-4090-b566-b77d117321f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.loadtxt(\"./saved_sims/figure_simulations.csv\", delimiter = \",\")\n",
    "\n",
    "# Reshape for embedding\n",
    "X = X.reshape(X.shape[0], 1, X.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5589cc3-92ad-47e0-bb08-3c7f5a92a37d",
   "metadata": {},
   "source": [
    "Now we load in the model for 2D embedding of the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f16b056-8640-46d9-a600-dcea3ae67110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters used for original training\n",
    "hp = {\n",
    "    \"in_channels\" : 1, \n",
    "    \"channels\": 10, \n",
    "    \"depth\": 10,\n",
    "    \"reduced_size\" : 2,\n",
    "    \"out_channels\" : 2, \n",
    "    \"kernel_size\": 3,\n",
    "    \"window_length\":133,\n",
    "    \"lr\": 1e-3, \n",
    "    \"epochs\": 1000,\n",
    "    \"batch_size\": 300, \n",
    "    \"weight_decay\":0.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861e752a-8bff-4805-a3dc-4201b2d9e455",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH =   \"./saved_params/2dAE.pth\"\n",
    "trained_model = CausalAE(hp)\n",
    "trained_model.load_state_dict(torch.load(PATH));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449ae939-324e-461f-92cb-daf666e8091f",
   "metadata": {},
   "source": [
    "As before we plot the original dataset, the embeddings, and the reconstructions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9eb1e7-d8a8-4249-8b62-1f17d1cb930f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the encoder and decoder\n",
    "encoder = trained_model.encoder.cpu()\n",
    "decoder = trained_model.decoder.cpu()\n",
    "\n",
    "# Switch into evaluation mode\n",
    "encoder.eval()\n",
    "decoder.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c8e0e5-cf66-4a9e-96c3-fc041e9172d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = encoder(torch.Tensor(X)).detach().numpy().T;\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7845e209-fcb1-41a3-84ba-3022b51349d6",
   "metadata": {},
   "source": [
    "In 2 dimensions we plot the entire latent distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58fe089-709e-4aad-8faf-057f923b1a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (5,5))\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.scatter(embeddings[0,:], embeddings[1,:], s = 10)\n",
    "plt.xlabel(\"Latent 1\")\n",
    "plt.ylabel(\"Latent 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5514a5c7-3d61-49ac-b85d-bae03c9261b5",
   "metadata": {},
   "source": [
    "As anticipated, the distribution no longer follows a simple one-dimensional shape, consistent with the underlying generative model no longer exhibiting a clear 1D structure.  We can also plot specific subset of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2223bd8f-f8e2-4892-b3ca-8a7df8609903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose ten curves at random\n",
    "subset = torch.Tensor(X[np.random.randint(0,X.shape[0], size = 5), :,:])\n",
    "\n",
    "# Generate embeddings and reconstructions\n",
    "embeddings_sub = encoder(subset)\n",
    "recons = decoder(embeddings_sub).cpu().detach()\n",
    "\n",
    "# Transfer to cpu and drop gradients to enable plotting\n",
    "embeddings_sub = embeddings_sub.cpu().detach()\n",
    "subset = subset.cpu().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8c2595-e977-42ee-9390-5a4ff5ddc5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot initial, embeddings, and reconstructions\n",
    "fig, axs = plt.subplots(1,3, figsize = (18,6))\n",
    "axs = axs.flatten()\n",
    "\n",
    "axs[0].plot(subset.squeeze().T, color = 'red')\n",
    "axs[0].set_title(\"Originals\")\n",
    "\n",
    "axs[1].scatter(embeddings_sub[:,0],embeddings_sub[:,1], color = \"red\")\n",
    "axs[1].set_xticks([])\n",
    "axs[1].set_yticks([])\n",
    "axs[1].set_title(\"Embeddings\")\n",
    "\n",
    "axs[2].plot(recons.squeeze().T, color = 'red')\n",
    "axs[2].set_title(\"Reconstructions\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ea8030-a3ff-46e1-b7a1-65433a2b8fe4",
   "metadata": {},
   "source": [
    "Lastly we can also look at the principal component decomposition in the latent space to analyze the structure of the learned embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8925e0f0-4ad5-4fef-ab28-d2552fd494c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Compute a PCA decomposition of the dataset\n",
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(embeddings.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223d05c1-7baf-4e61-843f-c1545e02ffce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the variance explaiend by each principal component\n",
    "\n",
    "variances = pca.explained_variance_ratio_\n",
    "\n",
    "# Plot formatting\n",
    "plt.figure(figsize = (4,4))\n",
    "plt.bar([f\"{x+1}\" for x in range(variances.shape[0])],height = variances)\n",
    "plt.ylim(0,1.0)\n",
    "plt.locator_params(axis='y', nbins=3)\n",
    "plt.title(\"Variance Explained by Principal Component\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cb9d5c-69e4-4e68-8018-fe0f1ccf9668",
   "metadata": {},
   "source": [
    "#### Analyzing `E = 10` Embeddings\n",
    "\n",
    "We repeat the same analysis except for `E = 10` for the embedding dimension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fd52d5-abe0-4c2f-a243-7c77085d96f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters used for original training\n",
    "hp = {\n",
    "    \"in_channels\" : 1, \n",
    "    \"channels\": 10, \n",
    "    \"depth\": 10,\n",
    "    \"reduced_size\" : 10,\n",
    "    \"out_channels\" : 10, \n",
    "    \"kernel_size\": 3,\n",
    "    \"window_length\":133,\n",
    "    \"lr\": 1e-3, \n",
    "    \"epochs\": 1000,\n",
    "    \"batch_size\": 300, \n",
    "    \"weight_decay\":0.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acabfb6-83f9-4023-913e-699d52574b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH =   \"./saved_params/10dAE.pth\"\n",
    "trained_model = CausalAE(hp)\n",
    "trained_model.load_state_dict(torch.load(PATH));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ed7aa5-d9ec-411c-8e61-dc3a5f185225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the encoder and decoder\n",
    "encoder = trained_model.encoder.cpu().double()\n",
    "decoder = trained_model.decoder.cpu().double()\n",
    "\n",
    "# Switch into evaluation mode\n",
    "encoder.eval()\n",
    "decoder.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8d65e9-fda7-4342-a7db-5747fd778c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = encoder(torch.Tensor(X).double())\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5604bcf9-0d48-4d2f-b411-16b54697d781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose ten curves at random\n",
    "subset = torch.Tensor(X[np.random.randint(0,X.shape[0], size = 5), :,:]).double()\n",
    "\n",
    "# Generate embeddings and reconstructions\n",
    "embeddings_sub = encoder(subset)\n",
    "recons = decoder(embeddings_sub).cpu().detach()\n",
    "\n",
    "# Transfer to cpu and drop gradients to enable plotting\n",
    "embeddings_sub = embeddings_sub.cpu().detach()\n",
    "subset = subset.cpu().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dbcf67-4b64-43af-9171-736ea3aa4cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot initial, embeddings, and reconstructions\n",
    "fig, axs = plt.subplots(1,2, figsize = (18,6))\n",
    "axs = axs.flatten()\n",
    "\n",
    "axs[0].plot(subset.squeeze().T, color = 'red')\n",
    "axs[0].set_title(\"Originals\")\n",
    "\n",
    "axs[1].plot(recons.squeeze().T, color = 'red')\n",
    "axs[1].set_title(\"Reconstructions\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef89b65d-0816-4f24-89a9-1959a9b4e303",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Compute a PCA decomposition of the dataset\n",
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(embeddings.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0ec406-063c-464a-ac58-d38e66093076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the variance explaiend by each principal component\n",
    "\n",
    "variances = pca.explained_variance_ratio_\n",
    "\n",
    "# Plot formatting\n",
    "plt.figure(figsize = (4,4))\n",
    "plt.bar([f\"{x+1}\" for x in range(variances.shape[0])],height = variances)\n",
    "plt.ylim(0,1.0)\n",
    "plt.locator_params(axis='y', nbins=3)\n",
    "plt.title(\"Variance Explained by Principal Component\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
